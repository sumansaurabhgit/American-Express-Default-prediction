{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541b1a24",
   "metadata": {
    "papermill": {
     "duration": 0.006268,
     "end_time": "2022-06-07T16:42:10.201779",
     "exception": false,
     "start_time": "2022-06-07T16:42:10.195511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### In this notebook, we use [RAPIDS cudf](https://github.com/rapidsai/cudf) to create a bunch of useful features and train XGB models. The entire pipeline is lightning-fast thanks to GPU end-to-end acceleration. Train time is 20 mins and test time is 5 mins. The CV is score is `0.795` and LB score is `0.795`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df7d463",
   "metadata": {
    "papermill": {
     "duration": 0.004732,
     "end_time": "2022-06-07T16:42:10.211200",
     "exception": false,
     "start_time": "2022-06-07T16:42:10.206468",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### What you might find useful from this notebook:\n",
    "### - Super fast pipeline. LB 0.795 in 25 mins!\n",
    "### - \"After-pay\" features. It makes intuitive semse that subtracting the payments from balance/spend etc provides new information about the users' behavior.\n",
    "### - Feature selection and hyperparameter tuning. Hundreds of GPU hours are burned to get these numbers. :P\n",
    "### - Scalable streaming prediction. Each time only a chunk of test data is read, processed and predicted. If more features are added, you could simply make `chunks` bigger and never worry about GPU out of memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22355c5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:10.222571Z",
     "iopub.status.busy": "2022-06-07T16:42:10.222044Z",
     "iopub.status.idle": "2022-06-07T16:42:10.240833Z",
     "shell.execute_reply": "2022-06-07T16:42:10.239460Z"
    },
    "papermill": {
     "duration": 0.028713,
     "end_time": "2022-06-07T16:42:10.244497",
     "exception": false,
     "start_time": "2022-06-07T16:42:10.215784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/amex-data-integer-dtypes-parquet-format/train.parquet\n",
      "/kaggle/input/amex-data-integer-dtypes-parquet-format/test.parquet\n",
      "/kaggle/input/amex-default-prediction/sample_submission.csv\n",
      "/kaggle/input/amex-default-prediction/train_data.csv\n",
      "/kaggle/input/amex-default-prediction/test_data.csv\n",
      "/kaggle/input/amex-default-prediction/train_labels.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8160dc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:10.255266Z",
     "iopub.status.busy": "2022-06-07T16:42:10.254961Z",
     "iopub.status.idle": "2022-06-07T16:42:14.899938Z",
     "shell.execute_reply": "2022-06-07T16:42:14.898903Z"
    },
    "papermill": {
     "duration": 4.652739,
     "end_time": "2022-06-07T16:42:14.902096",
     "exception": false,
     "start_time": "2022-06-07T16:42:10.249357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'21.10.01'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cudf\n",
    "import cupy\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "cudf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2544532c",
   "metadata": {
    "papermill": {
     "duration": 0.004859,
     "end_time": "2022-06-07T16:42:14.912329",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.907470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d19bc3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:14.923997Z",
     "iopub.status.busy": "2022-06-07T16:42:14.923675Z",
     "iopub.status.idle": "2022-06-07T16:42:14.949860Z",
     "shell.execute_reply": "2022-06-07T16:42:14.948855Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.035014,
     "end_time": "2022-06-07T16:42:14.952292",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.917278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_not_used():\n",
    "    # cid is the label encode of customer_ID\n",
    "    # row_id indicates the order of rows\n",
    "    return ['row_id', 'customer_ID', 'target', 'cid', 'S_2']\n",
    "    \n",
    "def preprocess(df):\n",
    "    df['row_id'] = cupy.arange(df.shape[0])\n",
    "    not_used = get_not_used()\n",
    "    cat_cols = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120',\n",
    "                'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col not in not_used+cat_cols:\n",
    "            df[col] = df[col].round(2)\n",
    "\n",
    "    # compute \"after pay\" features\n",
    "    for bcol in [f'B_{i}' for i in [11,14,17]]+['D_39','D_131']+[f'S_{i}' for i in [16,23]]:\n",
    "        for pcol in ['P_2','P_3']:\n",
    "            if bcol in df.columns:\n",
    "                df[f'{bcol}-{pcol}'] = df[bcol] - df[pcol]\n",
    "\n",
    "    df['S_2'] = cudf.to_datetime(df['S_2'])\n",
    "    df['cid'], _ = df.customer_ID.factorize()\n",
    "        \n",
    "    num_cols = [col for col in df.columns if col not in cat_cols+not_used]\n",
    "    \n",
    "    dgs = add_stats_step(df, num_cols)\n",
    "        \n",
    "    # cudf merge changes row orders\n",
    "    # restore the original row order by sorting row_id\n",
    "    df = df.sort_values('row_id')\n",
    "    df = df.drop(['row_id'],axis=1)\n",
    "    return df, dgs\n",
    "\n",
    "def add_stats_step(df, cols):\n",
    "    n = 50\n",
    "    dgs = []\n",
    "    for i in range(0,len(cols),n):\n",
    "        s = i\n",
    "        e = min(s+n, len(cols))\n",
    "        dg = add_stats_one_shot(df, cols[s:e])\n",
    "        dgs.append(dg)\n",
    "    return dgs\n",
    "\n",
    "def add_stats_one_shot(df, cols):\n",
    "    stats = ['mean','std']\n",
    "    dg = df.groupby('customer_ID').agg({col:stats for col in cols})\n",
    "    out_cols = []\n",
    "    for col in cols:\n",
    "        out_cols.extend([f'{col}_{s}' for s in stats])\n",
    "    dg.columns = out_cols\n",
    "    dg = dg.reset_index()\n",
    "    return dg\n",
    "\n",
    "def load_test_iter(path, chunks=4):\n",
    "    \n",
    "    test_rows = 11363762\n",
    "    chunk_rows = test_rows // chunks\n",
    "    \n",
    "    test = cudf.read_parquet(f'{path}/test.parquet',\n",
    "                             columns=['customer_ID','S_2'],\n",
    "                             num_rows=test_rows)\n",
    "    test = get_segment(test)\n",
    "    start = 0\n",
    "    while start < test.shape[0]:\n",
    "        if start+chunk_rows < test.shape[0]:\n",
    "            end = test['cus_count'].values[start+chunk_rows]\n",
    "        else:\n",
    "            end = test['cus_count'].values[-1]\n",
    "        end = int(end)\n",
    "        df = cudf.read_parquet(f'{path}/test.parquet',\n",
    "                               num_rows = end-start, skiprows=start)\n",
    "        start = end\n",
    "        yield process_data(df)\n",
    "    \n",
    "\n",
    "def load_train(path):\n",
    "    train = cudf.read_parquet(f'{path}/train.parquet')\n",
    "    \n",
    "    train = process_data(train)\n",
    "    trainl = cudf.read_csv(f'../input/amex-default-prediction/train_labels.csv')\n",
    "    train = train.merge(trainl, on='customer_ID', how='left')\n",
    "    return train\n",
    "\n",
    "def process_data(df):\n",
    "    df,dgs = preprocess(df)\n",
    "    df = df.drop_duplicates('customer_ID',keep='last')\n",
    "    for dg in dgs:\n",
    "        df = df.merge(dg, on='customer_ID', how='left')\n",
    "    diff_cols = [col for col in df.columns if col.endswith('_diff')]\n",
    "    df = df.drop(diff_cols,axis=1)\n",
    "    return df\n",
    "\n",
    "def get_segment(test):\n",
    "    dg = test.groupby('customer_ID').agg({'S_2':'count'})\n",
    "    dg.columns = ['cus_count']\n",
    "    dg = dg.reset_index()\n",
    "    dg['cid'],_ = dg['customer_ID'].factorize()\n",
    "    dg = dg.sort_values('cid')\n",
    "    dg['cus_count'] = dg['cus_count'].cumsum()\n",
    "    \n",
    "    test = test.merge(dg, on='customer_ID', how='left')\n",
    "    test = test.sort_values(['cid','S_2'])\n",
    "    assert test['cus_count'].values[-1] == test.shape[0]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd53683",
   "metadata": {
    "papermill": {
     "duration": 0.00492,
     "end_time": "2022-06-07T16:42:14.962224",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.957304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### XGB Params and utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dc4005e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:14.973389Z",
     "iopub.status.busy": "2022-06-07T16:42:14.973081Z",
     "iopub.status.idle": "2022-06-07T16:42:14.982253Z",
     "shell.execute_reply": "2022-06-07T16:42:14.981286Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.017364,
     "end_time": "2022-06-07T16:42:14.984338",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.966974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_train(x, y, xt, yt):\n",
    "    print(\"# of features:\", x.shape[1])\n",
    "    assert x.shape[1] == xt.shape[1]\n",
    "    dtrain = xgb.DMatrix(data=x, label=y)\n",
    "    dvalid = xgb.DMatrix(data=xt, label=yt)\n",
    "    params = {\n",
    "            'objective': 'binary:logistic', \n",
    "            'tree_method': 'gpu_hist', \n",
    "            'max_depth': 7,\n",
    "            'subsample':0.88,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'gamma':1.5,\n",
    "            'min_child_weight':8,\n",
    "            'lambda':70,\n",
    "            'eta':0.03,\n",
    "    }\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    bst = xgb.train(params, dtrain=dtrain,\n",
    "                num_boost_round=2600,evals=watchlist,\n",
    "                early_stopping_rounds=500, feval=xgb_amex, maximize=True,\n",
    "                verbose_eval=100)\n",
    "    print('best ntree_limit:', bst.best_ntree_limit)\n",
    "    print('best score:', bst.best_score)\n",
    "    return bst.predict(dvalid, iteration_range=(0,bst.best_ntree_limit)), bst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913ecee",
   "metadata": {
    "papermill": {
     "duration": 0.004691,
     "end_time": "2022-06-07T16:42:14.994005",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.989314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab9838a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:15.006016Z",
     "iopub.status.busy": "2022-06-07T16:42:15.005168Z",
     "iopub.status.idle": "2022-06-07T16:42:15.025489Z",
     "shell.execute_reply": "2022-06-07T16:42:15.024567Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.028302,
     "end_time": "2022-06-07T16:42:15.027542",
     "exception": false,
     "start_time": "2022-06-07T16:42:14.999240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgb_amex(y_pred, y_true):\n",
    "    return 'amex', amex_metric_np(y_pred,y_true.get_label())\n",
    "\n",
    "# Created by https://www.kaggle.com/yunchonggan\n",
    "# https://www.kaggle.com/competitions/amex-default-prediction/discussion/328020\n",
    "def amex_metric_np(preds: np.ndarray, target: np.ndarray) -> float:\n",
    "    indices = np.argsort(preds)[::-1]\n",
    "    preds, target = preds[indices], target[indices]\n",
    "\n",
    "    weight = 20.0 - target * 19.0\n",
    "    cum_norm_weight = (weight / weight.sum()).cumsum()\n",
    "    four_pct_mask = cum_norm_weight <= 0.04\n",
    "    d = np.sum(target[four_pct_mask]) / np.sum(target)\n",
    "\n",
    "    weighted_target = target * weight\n",
    "    lorentz = (weighted_target / weighted_target.sum()).cumsum()\n",
    "    gini = ((lorentz - cum_norm_weight) * weight).sum()\n",
    "\n",
    "    n_pos = np.sum(target)\n",
    "    n_neg = target.shape[0] - n_pos\n",
    "    gini_max = 10 * n_neg * (n_pos + 20 * n_neg - 19) / (n_pos + 20 * n_neg)\n",
    "\n",
    "    g = gini / gini_max\n",
    "    return 0.5 * (g + d)\n",
    "\n",
    "# we still need the official metric since the faster version above is slightly off\n",
    "import pandas as pd\n",
    "def amex_metric(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "\n",
    "    def top_four_percent_captured(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        four_pct_cutoff = int(0.04 * df['weight'].sum())\n",
    "        df['weight_cumsum'] = df['weight'].cumsum()\n",
    "        df_cutoff = df.loc[df['weight_cumsum'] <= four_pct_cutoff]\n",
    "        return (df_cutoff['target'] == 1).sum() / (df['target'] == 1).sum()\n",
    "        \n",
    "    def weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        df = (pd.concat([y_true, y_pred], axis='columns')\n",
    "              .sort_values('prediction', ascending=False))\n",
    "        df['weight'] = df['target'].apply(lambda x: 20 if x==0 else 1)\n",
    "        df['random'] = (df['weight'] / df['weight'].sum()).cumsum()\n",
    "        total_pos = (df['target'] * df['weight']).sum()\n",
    "        df['cum_pos_found'] = (df['target'] * df['weight']).cumsum()\n",
    "        df['lorentz'] = df['cum_pos_found'] / total_pos\n",
    "        df['gini'] = (df['lorentz'] - df['random']) * df['weight']\n",
    "        return df['gini'].sum()\n",
    "\n",
    "    def normalized_weighted_gini(y_true: pd.DataFrame, y_pred: pd.DataFrame) -> float:\n",
    "        y_true_pred = y_true.rename(columns={'target': 'prediction'})\n",
    "        return weighted_gini(y_true, y_pred) / weighted_gini(y_true, y_true_pred)\n",
    "\n",
    "    g = normalized_weighted_gini(y_true, y_pred)\n",
    "    d = top_four_percent_captured(y_true, y_pred)\n",
    "\n",
    "    return 0.5 * (g + d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5771824",
   "metadata": {
    "papermill": {
     "duration": 0.004815,
     "end_time": "2022-06-07T16:42:15.037162",
     "exception": false,
     "start_time": "2022-06-07T16:42:15.032347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load data and add feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6a1a73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:15.048153Z",
     "iopub.status.busy": "2022-06-07T16:42:15.047736Z",
     "iopub.status.idle": "2022-06-07T16:42:46.904575Z",
     "shell.execute_reply": "2022-06-07T16:42:46.902971Z"
    },
    "papermill": {
     "duration": 31.870976,
     "end_time": "2022-06-07T16:42:46.912976",
     "exception": false,
     "start_time": "2022-06-07T16:42:15.042000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.87 s, sys: 4.06 s, total: 12.9 s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = '../input/amex-data-integer-dtypes-parquet-format'\n",
    "train = load_train(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671a0f92",
   "metadata": {
    "papermill": {
     "duration": 0.00552,
     "end_time": "2022-06-07T16:42:46.925316",
     "exception": false,
     "start_time": "2022-06-07T16:42:46.919796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Train XGB in K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eda97ae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T16:42:46.937161Z",
     "iopub.status.busy": "2022-06-07T16:42:46.936788Z",
     "iopub.status.idle": "2022-06-07T17:03:16.811465Z",
     "shell.execute_reply": "2022-06-07T17:03:16.809370Z"
    },
    "papermill": {
     "duration": 1229.88436,
     "end_time": "2022-06-07T17:03:16.814880",
     "exception": false,
     "start_time": "2022-06-07T16:42:46.930520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n",
      "  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.67405\ttrain-amex:0.69793\teval-logloss:0.67411\teval-amex:0.68842\n",
      "[100]\ttrain-logloss:0.24161\ttrain-amex:0.78181\teval-logloss:0.24773\teval-amex:0.77064\n",
      "[200]\ttrain-logloss:0.21745\ttrain-amex:0.79694\teval-logloss:0.22756\teval-amex:0.78065\n",
      "[300]\ttrain-logloss:0.20899\ttrain-amex:0.80891\teval-logloss:0.22284\teval-amex:0.78649\n",
      "[400]\ttrain-logloss:0.20349\ttrain-amex:0.81751\teval-logloss:0.22050\teval-amex:0.78858\n",
      "[500]\ttrain-logloss:0.19899\ttrain-amex:0.82487\teval-logloss:0.21913\teval-amex:0.78974\n",
      "[600]\ttrain-logloss:0.19514\ttrain-amex:0.83173\teval-logloss:0.21829\teval-amex:0.79211\n",
      "[700]\ttrain-logloss:0.19182\ttrain-amex:0.83690\teval-logloss:0.21771\teval-amex:0.79222\n",
      "[800]\ttrain-logloss:0.18856\ttrain-amex:0.84236\teval-logloss:0.21723\teval-amex:0.79224\n",
      "[900]\ttrain-logloss:0.18544\ttrain-amex:0.84764\teval-logloss:0.21689\teval-amex:0.79220\n",
      "[1000]\ttrain-logloss:0.18248\ttrain-amex:0.85292\teval-logloss:0.21663\teval-amex:0.79238\n",
      "[1100]\ttrain-logloss:0.17947\ttrain-amex:0.85853\teval-logloss:0.21639\teval-amex:0.79329\n",
      "[1200]\ttrain-logloss:0.17672\ttrain-amex:0.86348\teval-logloss:0.21621\teval-amex:0.79335\n",
      "[1300]\ttrain-logloss:0.17398\ttrain-amex:0.86826\teval-logloss:0.21605\teval-amex:0.79323\n",
      "[1400]\ttrain-logloss:0.17137\ttrain-amex:0.87295\teval-logloss:0.21594\teval-amex:0.79357\n",
      "[1500]\ttrain-logloss:0.16877\ttrain-amex:0.87756\teval-logloss:0.21586\teval-amex:0.79374\n",
      "[1600]\ttrain-logloss:0.16628\ttrain-amex:0.88202\teval-logloss:0.21576\teval-amex:0.79358\n",
      "[1700]\ttrain-logloss:0.16370\ttrain-amex:0.88658\teval-logloss:0.21574\teval-amex:0.79362\n",
      "[1800]\ttrain-logloss:0.16126\ttrain-amex:0.89089\teval-logloss:0.21572\teval-amex:0.79397\n",
      "[1900]\ttrain-logloss:0.15893\ttrain-amex:0.89519\teval-logloss:0.21569\teval-amex:0.79439\n",
      "[2000]\ttrain-logloss:0.15647\ttrain-amex:0.89952\teval-logloss:0.21565\teval-amex:0.79429\n",
      "[2100]\ttrain-logloss:0.15417\ttrain-amex:0.90339\teval-logloss:0.21561\teval-amex:0.79483\n",
      "[2200]\ttrain-logloss:0.15192\ttrain-amex:0.90720\teval-logloss:0.21561\teval-amex:0.79503\n",
      "[2300]\ttrain-logloss:0.14979\ttrain-amex:0.91096\teval-logloss:0.21563\teval-amex:0.79506\n",
      "[2400]\ttrain-logloss:0.14766\ttrain-amex:0.91478\teval-logloss:0.21563\teval-amex:0.79477\n",
      "[2500]\ttrain-logloss:0.14553\ttrain-amex:0.91840\teval-logloss:0.21567\teval-amex:0.79492\n",
      "[2599]\ttrain-logloss:0.14345\ttrain-amex:0.92178\teval-logloss:0.21570\teval-amex:0.79462\n",
      "best ntree_limit: 2271\n",
      "best score: 0.795432\n",
      "Fold 0 amex 0.7952\n",
      "# of features: 584\n",
      "[0]\ttrain-logloss:0.67404\ttrain-amex:0.69930\teval-logloss:0.67407\teval-amex:0.69644\n",
      "[100]\ttrain-logloss:0.24207\ttrain-amex:0.78130\teval-logloss:0.24653\teval-amex:0.76896\n",
      "[200]\ttrain-logloss:0.21792\ttrain-amex:0.79612\teval-logloss:0.22611\teval-amex:0.78030\n",
      "[300]\ttrain-logloss:0.20924\ttrain-amex:0.80845\teval-logloss:0.22148\teval-amex:0.78609\n",
      "[400]\ttrain-logloss:0.20359\ttrain-amex:0.81712\teval-logloss:0.21929\teval-amex:0.78901\n",
      "[500]\ttrain-logloss:0.19917\ttrain-amex:0.82424\teval-logloss:0.21809\teval-amex:0.79114\n",
      "[600]\ttrain-logloss:0.19517\ttrain-amex:0.83097\teval-logloss:0.21722\teval-amex:0.79263\n",
      "[700]\ttrain-logloss:0.19172\ttrain-amex:0.83701\teval-logloss:0.21660\teval-amex:0.79358\n",
      "[800]\ttrain-logloss:0.18845\ttrain-amex:0.84277\teval-logloss:0.21623\teval-amex:0.79387\n",
      "[900]\ttrain-logloss:0.18531\ttrain-amex:0.84833\teval-logloss:0.21593\teval-amex:0.79439\n",
      "[1000]\ttrain-logloss:0.18226\ttrain-amex:0.85379\teval-logloss:0.21571\teval-amex:0.79437\n",
      "[1100]\ttrain-logloss:0.17935\ttrain-amex:0.85893\teval-logloss:0.21553\teval-amex:0.79467\n",
      "[1200]\ttrain-logloss:0.17655\ttrain-amex:0.86373\teval-logloss:0.21541\teval-amex:0.79478\n",
      "[1300]\ttrain-logloss:0.17386\ttrain-amex:0.86908\teval-logloss:0.21528\teval-amex:0.79509\n",
      "[1400]\ttrain-logloss:0.17114\ttrain-amex:0.87375\teval-logloss:0.21518\teval-amex:0.79499\n",
      "[1500]\ttrain-logloss:0.16854\ttrain-amex:0.87855\teval-logloss:0.21508\teval-amex:0.79577\n",
      "[1600]\ttrain-logloss:0.16586\ttrain-amex:0.88310\teval-logloss:0.21501\teval-amex:0.79573\n",
      "[1700]\ttrain-logloss:0.16343\ttrain-amex:0.88747\teval-logloss:0.21497\teval-amex:0.79542\n",
      "[1800]\ttrain-logloss:0.16098\ttrain-amex:0.89188\teval-logloss:0.21492\teval-amex:0.79588\n",
      "[1900]\ttrain-logloss:0.15859\ttrain-amex:0.89616\teval-logloss:0.21488\teval-amex:0.79612\n",
      "[2000]\ttrain-logloss:0.15633\ttrain-amex:0.90023\teval-logloss:0.21489\teval-amex:0.79557\n",
      "[2100]\ttrain-logloss:0.15409\ttrain-amex:0.90407\teval-logloss:0.21488\teval-amex:0.79626\n",
      "[2200]\ttrain-logloss:0.15193\ttrain-amex:0.90783\teval-logloss:0.21487\teval-amex:0.79653\n",
      "[2300]\ttrain-logloss:0.14993\ttrain-amex:0.91132\teval-logloss:0.21492\teval-amex:0.79620\n",
      "[2400]\ttrain-logloss:0.14782\ttrain-amex:0.91509\teval-logloss:0.21498\teval-amex:0.79601\n",
      "[2500]\ttrain-logloss:0.14582\ttrain-amex:0.91852\teval-logloss:0.21497\teval-amex:0.79660\n",
      "[2599]\ttrain-logloss:0.14374\ttrain-amex:0.92193\teval-logloss:0.21500\teval-amex:0.79656\n",
      "best ntree_limit: 2522\n",
      "best score: 0.796961\n",
      "Fold 1 amex 0.7977\n",
      "# of features: 584\n",
      "[0]\ttrain-logloss:0.67404\ttrain-amex:0.69907\teval-logloss:0.67415\teval-amex:0.69141\n",
      "[100]\ttrain-logloss:0.24123\ttrain-amex:0.78302\teval-logloss:0.24855\teval-amex:0.76914\n",
      "[200]\ttrain-logloss:0.21699\ttrain-amex:0.79784\teval-logloss:0.22856\teval-amex:0.77810\n",
      "[300]\ttrain-logloss:0.20843\ttrain-amex:0.81026\teval-logloss:0.22400\teval-amex:0.78330\n",
      "[400]\ttrain-logloss:0.20279\ttrain-amex:0.81918\teval-logloss:0.22173\teval-amex:0.78662\n",
      "[500]\ttrain-logloss:0.19839\ttrain-amex:0.82680\teval-logloss:0.22043\teval-amex:0.78822\n",
      "[600]\ttrain-logloss:0.19448\ttrain-amex:0.83303\teval-logloss:0.21956\teval-amex:0.78965\n",
      "[700]\ttrain-logloss:0.19109\ttrain-amex:0.83866\teval-logloss:0.21898\teval-amex:0.79030\n",
      "[800]\ttrain-logloss:0.18771\ttrain-amex:0.84420\teval-logloss:0.21855\teval-amex:0.79074\n",
      "[900]\ttrain-logloss:0.18444\ttrain-amex:0.84985\teval-logloss:0.21823\teval-amex:0.79174\n",
      "[1000]\ttrain-logloss:0.18142\ttrain-amex:0.85552\teval-logloss:0.21793\teval-amex:0.79189\n",
      "[1100]\ttrain-logloss:0.17857\ttrain-amex:0.86074\teval-logloss:0.21773\teval-amex:0.79231\n",
      "[1200]\ttrain-logloss:0.17590\ttrain-amex:0.86567\teval-logloss:0.21755\teval-amex:0.79267\n",
      "[1300]\ttrain-logloss:0.17304\ttrain-amex:0.87076\teval-logloss:0.21742\teval-amex:0.79272\n",
      "[1400]\ttrain-logloss:0.17053\ttrain-amex:0.87519\teval-logloss:0.21732\teval-amex:0.79343\n",
      "[1500]\ttrain-logloss:0.16792\ttrain-amex:0.87972\teval-logloss:0.21723\teval-amex:0.79377\n",
      "[1600]\ttrain-logloss:0.16573\ttrain-amex:0.88361\teval-logloss:0.21719\teval-amex:0.79378\n",
      "[1700]\ttrain-logloss:0.16325\ttrain-amex:0.88813\teval-logloss:0.21717\teval-amex:0.79425\n",
      "[1800]\ttrain-logloss:0.16067\ttrain-amex:0.89267\teval-logloss:0.21719\teval-amex:0.79420\n",
      "[1900]\ttrain-logloss:0.15808\ttrain-amex:0.89729\teval-logloss:0.21715\teval-amex:0.79347\n",
      "[2000]\ttrain-logloss:0.15564\ttrain-amex:0.90177\teval-logloss:0.21718\teval-amex:0.79358\n",
      "[2100]\ttrain-logloss:0.15324\ttrain-amex:0.90609\teval-logloss:0.21714\teval-amex:0.79383\n",
      "[2200]\ttrain-logloss:0.15111\ttrain-amex:0.90956\teval-logloss:0.21721\teval-amex:0.79349\n",
      "best ntree_limit: 1701\n",
      "best score: 0.794252\n",
      "Fold 2 amex 0.7940\n",
      "# of features: 584\n",
      "[0]\ttrain-logloss:0.67405\ttrain-amex:0.69871\teval-logloss:0.67417\teval-amex:0.69318\n",
      "[100]\ttrain-logloss:0.24134\ttrain-amex:0.78190\teval-logloss:0.24798\teval-amex:0.76813\n",
      "[200]\ttrain-logloss:0.21688\ttrain-amex:0.79739\teval-logloss:0.22812\teval-amex:0.77779\n",
      "[300]\ttrain-logloss:0.20824\ttrain-amex:0.80947\teval-logloss:0.22371\teval-amex:0.78314\n",
      "[400]\ttrain-logloss:0.20263\ttrain-amex:0.81804\teval-logloss:0.22172\teval-amex:0.78612\n",
      "[500]\ttrain-logloss:0.19808\ttrain-amex:0.82494\teval-logloss:0.22052\teval-amex:0.78751\n",
      "[600]\ttrain-logloss:0.19423\ttrain-amex:0.83144\teval-logloss:0.21979\teval-amex:0.78785\n",
      "[700]\ttrain-logloss:0.19078\ttrain-amex:0.83718\teval-logloss:0.21930\teval-amex:0.78904\n",
      "[800]\ttrain-logloss:0.18761\ttrain-amex:0.84272\teval-logloss:0.21894\teval-amex:0.78900\n",
      "[900]\ttrain-logloss:0.18442\ttrain-amex:0.84825\teval-logloss:0.21864\teval-amex:0.78962\n",
      "[1000]\ttrain-logloss:0.18153\ttrain-amex:0.85372\teval-logloss:0.21842\teval-amex:0.79065\n",
      "[1100]\ttrain-logloss:0.17850\ttrain-amex:0.85910\teval-logloss:0.21821\teval-amex:0.79055\n",
      "[1200]\ttrain-logloss:0.17576\ttrain-amex:0.86400\teval-logloss:0.21809\teval-amex:0.79135\n",
      "[1300]\ttrain-logloss:0.17307\ttrain-amex:0.86919\teval-logloss:0.21796\teval-amex:0.79147\n",
      "[1400]\ttrain-logloss:0.17048\ttrain-amex:0.87367\teval-logloss:0.21789\teval-amex:0.79213\n",
      "[1500]\ttrain-logloss:0.16781\ttrain-amex:0.87858\teval-logloss:0.21781\teval-amex:0.79170\n",
      "[1600]\ttrain-logloss:0.16531\ttrain-amex:0.88308\teval-logloss:0.21779\teval-amex:0.79232\n",
      "[1700]\ttrain-logloss:0.16287\ttrain-amex:0.88727\teval-logloss:0.21779\teval-amex:0.79201\n",
      "[1800]\ttrain-logloss:0.16053\ttrain-amex:0.89168\teval-logloss:0.21778\teval-amex:0.79222\n",
      "[1900]\ttrain-logloss:0.15811\ttrain-amex:0.89591\teval-logloss:0.21777\teval-amex:0.79206\n",
      "[2000]\ttrain-logloss:0.15577\ttrain-amex:0.90014\teval-logloss:0.21779\teval-amex:0.79201\n",
      "[2100]\ttrain-logloss:0.15367\ttrain-amex:0.90384\teval-logloss:0.21781\teval-amex:0.79228\n",
      "[2200]\ttrain-logloss:0.15145\ttrain-amex:0.90761\teval-logloss:0.21782\teval-amex:0.79198\n",
      "[2300]\ttrain-logloss:0.14941\ttrain-amex:0.91117\teval-logloss:0.21784\teval-amex:0.79181\n",
      "[2400]\ttrain-logloss:0.14723\ttrain-amex:0.91509\teval-logloss:0.21792\teval-amex:0.79141\n",
      "[2425]\ttrain-logloss:0.14674\ttrain-amex:0.91582\teval-logloss:0.21794\teval-amex:0.79138\n",
      "best ntree_limit: 1927\n",
      "best score: 0.792472\n",
      "Fold 3 amex 0.7930\n",
      "Average amex score: 0.7950\n",
      "CPU times: user 20min 21s, sys: 3.99 s, total: 20min 25s\n",
      "Wall time: 20min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "not_used = get_not_used()\n",
    "not_used = [i for i in not_used if i in train.columns]\n",
    "msgs = {}\n",
    "folds = 4\n",
    "score = 0\n",
    "\n",
    "for i in range(folds):\n",
    "    mask = train['cid']%folds == i\n",
    "    tr,va = train[~mask], train[mask]\n",
    "    \n",
    "    x, y = tr.drop(not_used, axis=1), tr['target']\n",
    "    xt, yt = va.drop(not_used, axis=1), va['target']\n",
    "    yp, bst = xgb_train(x, y, xt, yt)\n",
    "    bst.save_model(f'xgb_{i}.json')\n",
    "    amex_score = amex_metric(pd.DataFrame({'target':yt.values.get()}), \n",
    "                                    pd.DataFrame({'prediction':yp}))\n",
    "    msg = f\"Fold {i} amex {amex_score:.4f}\"\n",
    "    print(msg)\n",
    "    score += amex_score\n",
    "score /= folds\n",
    "print(f\"Average amex score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b72df1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T17:03:16.845483Z",
     "iopub.status.busy": "2022-06-07T17:03:16.844949Z",
     "iopub.status.idle": "2022-06-07T17:03:17.074836Z",
     "shell.execute_reply": "2022-06-07T17:03:17.073947Z"
    },
    "papermill": {
     "duration": 0.247841,
     "end_time": "2022-06-07T17:03:17.077353",
     "exception": false,
     "start_time": "2022-06-07T17:03:16.829512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del train\n",
    "del tr,va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee00dae4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T17:03:17.108453Z",
     "iopub.status.busy": "2022-06-07T17:03:17.107427Z",
     "iopub.status.idle": "2022-06-07T17:11:33.475401Z",
     "shell.execute_reply": "2022-06-07T17:11:33.474268Z"
    },
    "papermill": {
     "duration": 496.38523,
     "end_time": "2022-06-07T17:11:33.477414",
     "exception": false,
     "start_time": "2022-06-07T17:03:17.092184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ntree_limit: 2271\n",
      "best ntree_limit: 2522\n",
      "best ntree_limit: 1701\n",
      "best ntree_limit: 1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [02:30<07:32, 150.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ntree_limit: 2271\n",
      "best ntree_limit: 2522\n",
      "best ntree_limit: 1701\n",
      "best ntree_limit: 1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [04:25<04:19, 129.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ntree_limit: 2271\n",
      "best ntree_limit: 2522\n",
      "best ntree_limit: 1701\n",
      "best ntree_limit: 1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [06:21<02:03, 123.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best ntree_limit: 2271\n",
      "best ntree_limit: 2522\n",
      "best ntree_limit: 1701\n",
      "best ntree_limit: 1927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [08:16<00:00, 124.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min, sys: 19.3 s, total: 13min 19s\n",
      "Wall time: 8min 16s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0d008d9d467dcf3100189da96d7150912c901a3a5bc8bd...</td>\n",
       "      <td>0.005170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0d014b0ec34bce4102fbd8cafc7e326258fa3edfb3b105...</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d00a388a8b850c23b1170756a029baf41db6edceed46c...</td>\n",
       "      <td>0.005478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0d016264c66b29086eeb2209ced2cbfa290d0705fc5867...</td>\n",
       "      <td>0.000638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d00923ba0cd2219d797733a624bdb34547fa93547dfac...</td>\n",
       "      <td>0.049893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  prediction\n",
       "0  0d008d9d467dcf3100189da96d7150912c901a3a5bc8bd...    0.005170\n",
       "1  0d014b0ec34bce4102fbd8cafc7e326258fa3edfb3b105...    0.000926\n",
       "2  0d00a388a8b850c23b1170756a029baf41db6edceed46c...    0.005478\n",
       "3  0d016264c66b29086eeb2209ced2cbfa290d0705fc5867...    0.000638\n",
       "4  0d00923ba0cd2219d797733a624bdb34547fa93547dfac...    0.049893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "cids = []\n",
    "yps = []\n",
    "chunks = 4\n",
    "for df in tqdm(load_test_iter(path,chunks),total=chunks):\n",
    "    cids.append(df['customer_ID'])\n",
    "    not_used = [i for i in not_used if i in df.columns]\n",
    "\n",
    "    yp = 0\n",
    "    for i in range(folds):\n",
    "        bst = xgb.Booster()\n",
    "        bst.load_model(f'xgb_{i}.json')\n",
    "        dx = xgb.DMatrix(df.drop(not_used, axis=1))\n",
    "        print('best ntree_limit:', bst.best_ntree_limit)\n",
    "        yp += bst.predict(dx, iteration_range=(0,bst.best_ntree_limit))\n",
    "    yps.append(yp/folds)\n",
    "    \n",
    "df = cudf.DataFrame()\n",
    "df['customer_ID'] = cudf.concat(cids)\n",
    "df['prediction'] = np.concatenate(yps)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05879e66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-07T17:11:33.507333Z",
     "iopub.status.busy": "2022-06-07T17:11:33.506310Z",
     "iopub.status.idle": "2022-06-07T17:11:33.697446Z",
     "shell.execute_reply": "2022-06-07T17:11:33.696268Z"
    },
    "papermill": {
     "duration": 0.208451,
     "end_time": "2022-06-07T17:11:33.700164",
     "exception": false,
     "start_time": "2022-06-07T17:11:33.491713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('sub.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1774.347036,
   "end_time": "2022-06-07T17:11:35.142176",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-06-07T16:42:00.795140",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
